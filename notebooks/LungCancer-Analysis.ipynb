{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b1b358",
   "metadata": {},
   "source": [
    "# Disease Trend Analysis: Lung Cancer & Air Pollution Study\n",
    "\n",
    "---\n",
    "\n",
    "## Project Information\n",
    "\n",
    "**Project Title:** Comprehensive Analysis of Lung Cancer Trends and Air Pollution Correlation Globally\n",
    "\n",
    "**Author:** Sanaullah Turab  \n",
    "**Enrollment:** 01-136242-026  \n",
    "**Class:** BSAI  \n",
    "**Section:** 3A  \n",
    "**Date:** December 9, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Project Description\n",
    "\n",
    "This project presents a comprehensive data analysis of lung cancer cases and global air pollution patterns. The analysis utilizes two primary datasets:\n",
    "\n",
    "1. **Medical Dataset**: 890,000 lung cancer patient records from 27 European countries (2014-2024) including demographics, risk factors, comorbidities, treatment types, and survival outcomes\n",
    "2. **Air Pollution Dataset**: PM2.5 pollution measurements from 6,985 cities across 133 countries globally (2017-2023)\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Perform comprehensive data preprocessing, cleaning, and normalization\n",
    "- Conduct exploratory data analysis (EDA) to identify patterns and trends\n",
    "- Visualize key relationships between variables using Matplotlib and Seaborn\n",
    "- Analyze global air pollution trends and patterns across continents\n",
    "- Investigate the correlation between air pollution levels and lung cancer incidence in European context\n",
    "- Examine the impact of risk factors (smoking, BMI, comorbidities) on survival outcomes\n",
    "- Compare pollution levels globally and correlate with European health outcomes\n",
    "- Provide data-driven insights and recommendations\n",
    "\n",
    "### Technologies Used\n",
    "\n",
    "- **Python 3.12** - Primary programming language\n",
    "- **Pandas & NumPy** - Data manipulation and numerical computations\n",
    "- **Matplotlib & Seaborn** - Data visualization\n",
    "- **Scikit-learn** - Data preprocessing and normalization\n",
    "- **SciPy** - Statistical analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866229f1",
   "metadata": {},
   "source": [
    "# 1. Library Imports\n",
    "\n",
    "This section imports all required Python libraries for data manipulation (Pandas, NumPy), visualization (Matplotlib, Seaborn), preprocessing (Scikit-learn), and statistical analysis (SciPy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0942b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All libraries imported successfully!\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Data Preprocessing and Normalization\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical Analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, ttest_ind, f_oneway\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Display settings for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8628c",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing - Medical Dataset\n",
    "\n",
    "Complete preprocessing pipeline for the lung cancer medical dataset (890,000 patient records). Includes duplicate removal, missing value handling, MinMaxScaler normalization (0-1 range), and dataset splitting into 3 parts for memory efficiency.\n",
    "\n",
    "**Note:** Code is commented out - preprocessing already completed. Normalized files saved in datasets folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0557ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical dataset preprocessing code available (commented out)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MEDICAL DATASET PREPROCESSING - COMMENTED OUT (Already Processed)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('../datasets/dataset_med.csv')\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"INITIAL DATASET INFO\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumn names and types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"CHECKING FOR DUPLICATES\")\n",
    "print(f\"{'='*50}\")\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"Removing {duplicates} duplicate rows...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"New shape after removing duplicates: {df.shape}\")\n",
    "else:\n",
    "    print(\"No duplicates found!\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"CHECKING FOR MISSING VALUES\")\n",
    "print(f\"{'='*50}\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing_Count': missing_values.values,\n",
    "    'Percentage': missing_percent.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No missing values found!\")\n",
    "\n",
    "# Handle missing values\n",
    "if len(missing_df) > 0:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"HANDLING MISSING VALUES\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                # For numerical columns, fill with median\n",
    "                median_val = df[col].median()\n",
    "                df[col].fillna(median_val, inplace=True)\n",
    "                print(f\"Filled {col} (numerical) with median: {median_val}\")\n",
    "            else:\n",
    "                # For categorical columns, fill with mode or 'Unknown'\n",
    "                if df[col].mode().shape[0] > 0:\n",
    "                    mode_val = df[col].mode()[0]\n",
    "                    df[col].fillna(mode_val, inplace=True)\n",
    "                    print(f\"Filled {col} (categorical) with mode: {mode_val}\")\n",
    "                else:\n",
    "                    df[col].fillna('Unknown', inplace=True)\n",
    "                    print(f\"Filled {col} (categorical) with 'Unknown'\")\n",
    "    \n",
    "    print(f\"\\nMissing values after handling: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Normalize numerical columns\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"NORMALIZING NUMERICAL COLUMNS\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f\"Numerical columns to normalize: {numerical_cols}\")\n",
    "\n",
    "if len(numerical_cols) > 0:\n",
    "    # Create a copy for normalized data\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Use MinMaxScaler (normalizes to 0-1 range)\n",
    "    scaler = MinMaxScaler()\n",
    "    df_normalized[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    \n",
    "    print(\"Normalization complete using MinMaxScaler (0-1 range)\")\n",
    "    print(\"\\nSample of normalized data:\")\n",
    "    print(df_normalized[numerical_cols].head())\n",
    "else:\n",
    "    df_normalized = df.copy()\n",
    "    print(\"No numerical columns to normalize\")\n",
    "\n",
    "# Split dataset into multiple files\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"SPLITTING DATASET INTO SMALLER FILES\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "total_rows = len(df_normalized)\n",
    "num_splits = 3  # Split into 3 files\n",
    "rows_per_split = total_rows // num_splits\n",
    "\n",
    "output_dir = '../datasets'\n",
    "\n",
    "for i in range(num_splits):\n",
    "    start_idx = i * rows_per_split\n",
    "    if i == num_splits - 1:\n",
    "        # Last split gets all remaining rows\n",
    "        end_idx = total_rows\n",
    "    else:\n",
    "        end_idx = (i + 1) * rows_per_split\n",
    "    \n",
    "    split_df = df_normalized.iloc[start_idx:end_idx]\n",
    "    output_file = os.path.join(output_dir, f'dataset_med_normalized_part{i+1}.csv')\n",
    "    split_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved part {i+1}: {output_file} ({len(split_df)} rows)\")\n",
    "\n",
    "# Save the complete normalized dataset as well\n",
    "complete_output = os.path.join(output_dir, 'dataset_med_normalized_complete.csv')\n",
    "df_normalized.to_csv(complete_output, index=False)\n",
    "print(f\"\\nSaved complete normalized dataset: {complete_output} ({len(df_normalized)} rows)\")\n",
    "\n",
    "# Generate summary report\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"SUMMARY REPORT\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Original dataset rows: {total_rows}\")\n",
    "print(f\"Duplicates removed: {duplicates}\")\n",
    "print(f\"Missing values handled: {len(missing_df)} columns\")\n",
    "print(f\"Numerical columns normalized: {len(numerical_cols)}\")\n",
    "print(f\"Dataset split into: {num_splits} files\")\n",
    "print(f\"\\nOutput files created:\")\n",
    "for i in range(num_splits):\n",
    "    print(f\"  - dataset_med_normalized_part{i+1}.csv\")\n",
    "print(f\"  - dataset_med_normalized_complete.csv\")\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(f\"{'='*50}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Medical dataset preprocessing code available (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f4b8e",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing - Air Pollution Dataset\n",
    "\n",
    "Complete preprocessing pipeline for air pollution data (6,985 cities, PM2.5 measurements 2017-2023). Handles 26.69% missing values using time series interpolation, country-level mean imputation, and global mean imputation. Includes duplicate detection and statistical report generation.\n",
    "\n",
    "**Note:** Code is commented out - preprocessing already completed. Normalized dataset saved as air_pollution_normalized.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41dcbe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air pollution dataset preprocessing code available (commented out)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AIR POLLUTION DATASET PREPROCESSING - COMMENTED OUT (Already Processed)\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    '''Load the air pollution dataset.'''\n",
    "    df = pd.read_csv('../datasets/air_pollution.csv')\n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head(10))\n",
    "    print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
    "    print(f\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    return df\n",
    "\n",
    "def check_duplicates(df):\n",
    "    '''Check for and remove duplicate records.'''\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CHECKING FOR DUPLICATES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    duplicates = df.duplicated()\n",
    "    num_duplicates = duplicates.sum()\n",
    "    print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "    \n",
    "    if num_duplicates > 0:\n",
    "        print(\"\\nDuplicate rows:\")\n",
    "        print(df[duplicates])\n",
    "        df_clean = df.drop_duplicates()\n",
    "        print(f\"\\nDataset shape after removing duplicates: {df_clean.shape}\")\n",
    "        return df_clean\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")\n",
    "        return df\n",
    "\n",
    "def analyze_missing_values(df):\n",
    "    '''Analyze missing values in the dataset.'''\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MISSING VALUE ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Column': missing_counts.index,\n",
    "        'Missing_Count': missing_counts.values,\n",
    "        'Missing_Percentage': missing_percentages.values\n",
    "    })\n",
    "    \n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(missing_df)\n",
    "    \n",
    "    total_missing = df.isnull().sum().sum()\n",
    "    total_cells = df.shape[0] * df.shape[1]\n",
    "    overall_missing_pct = (total_missing / total_cells) * 100\n",
    "    \n",
    "    print(f\"\\nTotal missing values: {total_missing} out of {total_cells} cells ({overall_missing_pct:.2f}%)\")\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    '''Handle missing values in the dataset.'''\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HANDLING MISSING VALUES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    id_cols = ['city', 'country']\n",
    "    year_cols = [col for col in df.columns if col not in id_cols]\n",
    "    \n",
    "    print(f\"\\nIdentifier columns: {id_cols}\")\n",
    "    print(f\"Year columns: {year_cols}\")\n",
    "    \n",
    "    # Check for missing values in identifier columns\n",
    "    for col in id_cols:\n",
    "        missing = df_clean[col].isnull().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"\\nWarning: {missing} missing values found in '{col}' column\")\n",
    "            df_clean = df_clean.dropna(subset=[col])\n",
    "            print(f\"Removed rows with missing '{col}'. New shape: {df_clean.shape}\")\n",
    "    \n",
    "    # Handle missing values in year columns\n",
    "    print(f\"\\nStrategy for year columns: Interpolation along rows (time series)\")\n",
    "    print(\"This will estimate missing values based on available years for each city.\")\n",
    "    \n",
    "    original_missing = df_clean[year_cols].isnull().sum().sum()\n",
    "    \n",
    "    # Interpolate across years for each city (row-wise)\n",
    "    df_clean[year_cols] = df_clean[year_cols].interpolate(method='linear', axis=1, limit_direction='both')\n",
    "    \n",
    "    remaining_missing = df_clean[year_cols].isnull().sum().sum()\n",
    "    \n",
    "    print(f\"\\nMissing values before interpolation: {original_missing}\")\n",
    "    print(f\"Missing values after interpolation: {remaining_missing}\")\n",
    "    \n",
    "    if remaining_missing > 0:\n",
    "        print(f\"\\nApplying country-level mean imputation for remaining missing values...\")\n",
    "        \n",
    "        for col in year_cols:\n",
    "            df_clean[col] = df_clean.groupby('country')[col].transform(\n",
    "                lambda x: x.fillna(x.mean())\n",
    "            )\n",
    "        \n",
    "        still_missing = df_clean[year_cols].isnull().sum().sum()\n",
    "        print(f\"Missing values after country-level imputation: {still_missing}\")\n",
    "        \n",
    "        if still_missing > 0:\n",
    "            print(f\"\\nApplying global mean imputation for any remaining missing values...\")\n",
    "            df_clean[year_cols] = df_clean[year_cols].fillna(df_clean[year_cols].mean())\n",
    "            \n",
    "            final_missing = df_clean[year_cols].isnull().sum().sum()\n",
    "            print(f\"Missing values after global imputation: {final_missing}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def save_cleaned_data(df):\n",
    "    '''Save the cleaned dataset.'''\n",
    "    output_path = '../datasets/air_pollution_normalized.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\n‚úì Cleaned dataset saved to: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Main preprocessing pipeline\n",
    "print(\"=\"*60)\n",
    "print(\"AIR POLLUTION DATASET PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_original = load_data()\n",
    "df = check_duplicates(df_original)\n",
    "missing_analysis = analyze_missing_values(df)\n",
    "df_clean = handle_missing_values(df)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOriginal dataset shape: {df_original.shape}\")\n",
    "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "print(f\"Rows removed: {df_original.shape[0] - df_clean.shape[0]}\")\n",
    "print(f\"\\nOriginal missing values: {df_original.isnull().sum().sum()}\")\n",
    "print(f\"Cleaned missing values: {df_clean.isnull().sum().sum()}\")\n",
    "\n",
    "year_cols = [col for col in df_clean.columns if col not in ['city', 'country']]\n",
    "print(\"\\nDescriptive statistics of cleaned data:\")\n",
    "print(df_clean[year_cols].describe())\n",
    "\n",
    "save_cleaned_data(df_clean)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\"\"\"\n",
    "\n",
    "print(\"Air pollution dataset preprocessing code available (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5200bc32",
   "metadata": {},
   "source": [
    "# 4. Load Datasets\n",
    "\n",
    "Loading datasets for analysis:\n",
    "- Medical dataset: Lung cancer patient records (Part 1 - split for memory efficiency)\n",
    "- Air pollution dataset: PM2.5 measurements across European cities (2017-2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7af78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASETS LOADED SUCCESSFULLY\n",
      "============================================================\n",
      "\n",
      "üìä Medical Dataset Info:\n",
      "   Shape: (296666, 17)\n",
      "   Columns: ['id', 'age', 'gender', 'country', 'diagnosis_date', 'cancer_stage', 'family_history', 'smoking_status', 'bmi', 'cholesterol_level', 'hypertension', 'asthma', 'cirrhosis', 'other_cancer', 'treatment_type', 'end_treatment_date', 'survived']\n",
      "   Memory: 149.68 MB\n",
      "\n",
      "üåç Air Pollution Dataset Info:\n",
      "   Shape: (6985, 9)\n",
      "   Columns: ['city', 'country', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "   Memory: 1.12 MB\n",
      "\n",
      "‚úì Data loading complete!\n",
      "   Memory: 149.68 MB\n",
      "\n",
      "üåç Air Pollution Dataset Info:\n",
      "   Shape: (6985, 9)\n",
      "   Columns: ['city', 'country', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "   Memory: 1.12 MB\n",
      "\n",
      "‚úì Data loading complete!\n"
     ]
    }
   ],
   "source": [
    "# Load the medical dataset (Part 1)\n",
    "# Files: lung_cancer_part1/2/3.csv are the normalized medical datasets\n",
    "df_medical = pd.read_csv('../datasets/lung_cancer_part1.csv')\n",
    "\n",
    "# Load the air pollution dataset\n",
    "# File: air_pollution.csv is the normalized air pollution dataset\n",
    "df_pollution = pd.read_csv('../datasets/air_pollution.csv')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASETS LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìä Medical Dataset Info:\")\n",
    "print(f\"   Shape: {df_medical.shape}\")\n",
    "print(f\"   Columns: {list(df_medical.columns)}\")\n",
    "print(f\"   Memory: {df_medical.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nüåç Air Pollution Dataset Info:\")\n",
    "print(f\"   Shape: {df_pollution.shape}\")\n",
    "print(f\"   Columns: {list(df_pollution.columns)}\")\n",
    "print(f\"   Memory: {df_pollution.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n‚úì Data loading complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d98cb1",
   "metadata": {},
   "source": [
    "# 5. Data Overview and Initial Exploration\n",
    "\n",
    "Examination of dataset structure, data types, and basic statistical summaries for both medical and air pollution datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e567f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MEDICAL DATASET - FIRST 10 ROWS\n",
      "============================================================\n",
      "     id   age  gender      country diagnosis_date cancer_stage family_history  \\\n",
      "0 0.000 0.600    Male       Sweden     2016-04-05      Stage I            Yes   \n",
      "1 0.000 0.460  Female  Netherlands     2023-04-20    Stage III            Yes   \n",
      "2 0.000 0.610  Female      Hungary     2023-04-05    Stage III            Yes   \n",
      "3 0.000 0.470  Female      Belgium     2016-02-05      Stage I             No   \n",
      "4 0.000 0.330    Male   Luxembourg     2023-11-29      Stage I             No   \n",
      "5 0.000 0.460    Male        Italy     2023-01-02      Stage I             No   \n",
      "6 0.000 0.450  Female      Croatia     2018-05-21    Stage III            Yes   \n",
      "7 0.000 0.470    Male      Denmark     2017-02-18     Stage IV            Yes   \n",
      "8 0.000 0.600    Male       Sweden     2021-03-21    Stage III            Yes   \n",
      "9 0.000 0.520    Male      Hungary     2021-11-30     Stage IV            Yes   \n",
      "\n",
      "   smoking_status   bmi  cholesterol_level  hypertension  asthma  cirrhosis  \\\n",
      "0  Passive Smoker 0.462              0.327         0.000   0.000      1.000   \n",
      "1  Passive Smoker 0.869              0.867         1.000   1.000      0.000   \n",
      "2   Former Smoker 0.966              0.787         1.000   1.000      0.000   \n",
      "3  Passive Smoker 0.931              0.607         1.000   1.000      0.000   \n",
      "4  Passive Smoker 0.128              0.187         0.000   0.000      0.000   \n",
      "5    Never Smoked 0.745              0.827         1.000   0.000      0.000   \n",
      "6  Passive Smoker 0.934              0.727         0.000   0.000      0.000   \n",
      "7   Former Smoker 0.338              0.300         1.000   1.000      0.000   \n",
      "8  Current Smoker 0.190              0.573         0.000   0.000      0.000   \n",
      "9  Current Smoker 0.045              0.220         1.000   0.000      0.000   \n",
      "\n",
      "   other_cancer treatment_type end_treatment_date  survived  \n",
      "0         0.000   Chemotherapy         2017-09-10     0.000  \n",
      "1         0.000        Surgery         2024-06-17     1.000  \n",
      "2         0.000       Combined         2024-04-09     0.000  \n",
      "3         0.000   Chemotherapy         2017-04-23     0.000  \n",
      "4         0.000       Combined         2025-01-08     0.000  \n",
      "5         0.000      Radiation         2024-12-27     0.000  \n",
      "6         0.000      Radiation         2019-05-06     1.000  \n",
      "7         0.000       Combined         2017-08-26     0.000  \n",
      "8         0.000   Chemotherapy         2022-03-07     0.000  \n",
      "9         1.000        Surgery         2023-11-29     0.000  \n",
      "\n",
      "============================================================\n",
      "MEDICAL DATASET - DATA TYPES\n",
      "============================================================\n",
      "id                    float64\n",
      "age                   float64\n",
      "gender                 object\n",
      "country                object\n",
      "diagnosis_date         object\n",
      "cancer_stage           object\n",
      "family_history         object\n",
      "smoking_status         object\n",
      "bmi                   float64\n",
      "cholesterol_level     float64\n",
      "hypertension          float64\n",
      "asthma                float64\n",
      "cirrhosis             float64\n",
      "other_cancer          float64\n",
      "treatment_type         object\n",
      "end_treatment_date     object\n",
      "survived              float64\n",
      "dtype: object\n",
      "\n",
      "============================================================\n",
      "MEDICAL DATASET - BASIC STATISTICS\n",
      "============================================================\n",
      "              id        age        bmi  cholesterol_level  hypertension  \\\n",
      "count 296666.000 296666.000 296666.000         296666.000    296666.000   \n",
      "mean       0.167      0.510      0.500              0.558         0.751   \n",
      "std        0.096      0.100      0.289              0.290         0.432   \n",
      "min        0.000      0.030      0.000              0.000         0.000   \n",
      "25%        0.083      0.440      0.252              0.307         1.000   \n",
      "50%        0.167      0.510      0.500              0.613         1.000   \n",
      "75%        0.250      0.580      0.752              0.807         1.000   \n",
      "max        0.333      0.970      1.000              1.000         1.000   \n",
      "\n",
      "          asthma  cirrhosis  other_cancer   survived  \n",
      "count 296666.000 296666.000    296666.000 296666.000  \n",
      "mean       0.469      0.225         0.089      0.220  \n",
      "std        0.499      0.418         0.284      0.414  \n",
      "min        0.000      0.000         0.000      0.000  \n",
      "25%        0.000      0.000         0.000      0.000  \n",
      "50%        0.000      0.000         0.000      0.000  \n",
      "75%        1.000      0.000         0.000      0.000  \n",
      "max        1.000      1.000         1.000      1.000  \n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of medical dataset\n",
    "print(\"=\"*60)\n",
    "print(\"MEDICAL DATASET - FIRST 10 ROWS\")\n",
    "print(\"=\"*60)\n",
    "print(df_medical.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEDICAL DATASET - DATA TYPES\")\n",
    "print(\"=\"*60)\n",
    "print(df_medical.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEDICAL DATASET - BASIC STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(df_medical.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d9fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AIR POLLUTION DATASET - FIRST 10 ROWS\n",
      "============================================================\n",
      "           city      country   2017   2018   2019   2020   2021   2022   2023\n",
      "0         Kabul  Afghanistan 61.800 61.800 58.800 46.500 37.500 17.100 18.100\n",
      "1        Tirana      Albania 16.000 16.000 16.000 16.000 12.500 14.500 14.400\n",
      "2       Algiers      Algeria 21.200 21.200 21.200 20.200 20.000 17.800 17.400\n",
      "3        Ordino      Andorra  7.400  7.400  7.400  7.400  7.300  5.400  5.300\n",
      "4        Luanda       Angola 15.900 15.900 15.900 13.000 11.000  8.800  8.700\n",
      "5  Buenos Aires    Argentina 12.400 12.400 12.400 14.200 13.600 14.200 14.200\n",
      "6       Cordoba    Argentina 10.300 10.300 10.300 10.300 10.300  8.700  8.700\n",
      "7  General Pico    Argentina  7.100  7.100  7.100  7.100  7.100  7.200  7.200\n",
      "8       Mendoza    Argentina  9.300  9.300  9.300  9.300  9.300  8.200  8.200\n",
      "9       Rafaela    Argentina 10.400 10.400 10.400 10.400 10.400 10.700 10.700\n",
      "\n",
      "============================================================\n",
      "AIR POLLUTION DATASET - DATA TYPES\n",
      "============================================================\n",
      "city        object\n",
      "country     object\n",
      "2017       float64\n",
      "2018       float64\n",
      "2019       float64\n",
      "2020       float64\n",
      "2021       float64\n",
      "2022       float64\n",
      "2023       float64\n",
      "dtype: object\n",
      "\n",
      "============================================================\n",
      "AIR POLLUTION DATASET - BASIC STATISTICS\n",
      "============================================================\n",
      "          2017     2018     2019     2020     2021     2022     2023\n",
      "count 6985.000 6985.000 6985.000 6985.000 6985.000 6985.000 6985.000\n",
      "mean    14.971   14.720   14.237   13.988   13.955   12.740   12.727\n",
      "std     13.475   12.762   11.825   11.167   11.184   10.742   10.789\n",
      "min      0.200    0.200    0.200    0.200    0.200    0.200    0.300\n",
      "25%      7.800    7.800    7.600    7.900    7.900    7.000    7.000\n",
      "50%     11.000   11.000   10.600   10.400   10.400    9.300    9.300\n",
      "75%     16.200   16.200   15.800   16.000   15.900   14.100   14.000\n",
      "max    175.900  175.900  175.900  175.900  175.900   97.400   97.400\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of air pollution dataset\n",
    "print(\"=\"*60)\n",
    "print(\"AIR POLLUTION DATASET - FIRST 10 ROWS\")\n",
    "print(\"=\"*60)\n",
    "print(df_pollution.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AIR POLLUTION DATASET - DATA TYPES\")\n",
    "print(\"=\"*60)\n",
    "print(df_pollution.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AIR POLLUTION DATASET - BASIC STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "year_cols = ['2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "print(df_pollution[year_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97cdaa7",
   "metadata": {},
   "source": [
    "# 6. Categorical Data Distribution Analysis\n",
    "\n",
    "Analysis of categorical variable distributions in the medical dataset including patient demographics (gender, country), cancer characteristics (stage, family history), lifestyle factors (smoking status), treatment types, survival outcomes, and comorbidity prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6796aae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATEGORICAL VARIABLE DISTRIBUTIONS\n",
      "============================================================\n",
      "\n",
      "1. GENDER DISTRIBUTION:\n",
      "gender\n",
      "Male      148372\n",
      "Female    148294\n",
      "Name: count, dtype: int64\n",
      "Percentage:\n",
      "gender\n",
      "Male     50.013\n",
      "Female   49.987\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "2. TOP 10 COUNTRIES BY PATIENT COUNT:\n",
      "country\n",
      "Ireland        11152\n",
      "Croatia        11124\n",
      "Malta          11111\n",
      "France         11072\n",
      "Belgium        11071\n",
      "Netherlands    11060\n",
      "Estonia        11050\n",
      "Sweden         11042\n",
      "Portugal       11039\n",
      "Spain          11038\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3. CANCER STAGE DISTRIBUTION:\n",
      "cancer_stage\n",
      "Stage III    74416\n",
      "Stage IV     74357\n",
      "Stage I      73987\n",
      "Stage II     73906\n",
      "Name: count, dtype: int64\n",
      "Percentage:\n",
      "cancer_stage\n",
      "Stage III   25.084\n",
      "Stage IV    25.064\n",
      "Stage I     24.939\n",
      "Stage II    24.912\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "4. FAMILY HISTORY OF CANCER:\n",
      "family_history\n",
      "No     148468\n",
      "Yes    148198\n",
      "Name: count, dtype: int64\n",
      "Percentage:\n",
      "family_history\n",
      "No    50.046\n",
      "Yes   49.954\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "5. SMOKING STATUS DISTRIBUTION:\n",
      "smoking_status\n",
      "Passive Smoker    74538\n",
      "Never Smoked      74282\n",
      "Current Smoker    74019\n",
      "Former Smoker     73827\n",
      "Name: count, dtype: int64\n",
      "Percentage:\n",
      "smoking_status\n",
      "Passive Smoker   25.125\n",
      "Never Smoked     25.039\n",
      "Current Smoker   24.950\n",
      "Former Smoker    24.886\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "6. TREATMENT TYPE DISTRIBUTION:\n",
      "treatment_type\n",
      "Chemotherapy    74589\n",
      "Surgery         74341\n",
      "Combined        74048\n",
      "Radiation       73688\n",
      "Name: count, dtype: int64\n",
      "Percentage:\n",
      "treatment_type\n",
      "Chemotherapy   25.142\n",
      "Surgery        25.059\n",
      "Combined       24.960\n",
      "Radiation      24.839\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "7. SURVIVAL STATUS:\n",
      "survived\n",
      "0.000    231383\n",
      "1.000     65283\n",
      "Name: count, dtype: int64\n",
      "Survival Rate: 22.01%\n",
      "\n",
      "8. COMORBIDITY PREVALENCE:\n",
      "Hypertension: 222767 patients (75.1%)\n",
      "Asthma: 139268 patients (46.9%)\n",
      "Cirrhosis: 66778 patients (22.5%)\n",
      "Other Cancer: 26284 patients (8.9%)\n",
      "Percentage:\n",
      "smoking_status\n",
      "Passive Smoker   25.125\n",
      "Never Smoked     25.039\n",
      "Current Smoker   24.950\n",
      "Former Smoker    24.886\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "6. TREATMENT TYPE DISTRIBUTION:\n",
      "treatment_type\n",
      "Chemotherapy    74589\n",
      "Surgery         74341\n",
      "Combined        74048\n",
      "Radiation       73688\n",
      "Name: count, dtype: int64\n",
      "Percentage:\n",
      "treatment_type\n",
      "Chemotherapy   25.142\n",
      "Surgery        25.059\n",
      "Combined       24.960\n",
      "Radiation      24.839\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "7. SURVIVAL STATUS:\n",
      "survived\n",
      "0.000    231383\n",
      "1.000     65283\n",
      "Name: count, dtype: int64\n",
      "Survival Rate: 22.01%\n",
      "\n",
      "8. COMORBIDITY PREVALENCE:\n",
      "Hypertension: 222767 patients (75.1%)\n",
      "Asthma: 139268 patients (46.9%)\n",
      "Cirrhosis: 66778 patients (22.5%)\n",
      "Other Cancer: 26284 patients (8.9%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze categorical distributions\n",
    "print(\"=\"*60)\n",
    "print(\"CATEGORICAL VARIABLE DISTRIBUTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Gender distribution\n",
    "print(\"\\n1. GENDER DISTRIBUTION:\")\n",
    "print(df_medical['gender'].value_counts())\n",
    "print(f\"Percentage:\\n{df_medical['gender'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Country distribution (top 10)\n",
    "print(\"\\n2. TOP 10 COUNTRIES BY PATIENT COUNT:\")\n",
    "print(df_medical['country'].value_counts().head(10))\n",
    "\n",
    "# Cancer stage distribution\n",
    "print(\"\\n3. CANCER STAGE DISTRIBUTION:\")\n",
    "print(df_medical['cancer_stage'].value_counts())\n",
    "print(f\"Percentage:\\n{df_medical['cancer_stage'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Family history\n",
    "print(\"\\n4. FAMILY HISTORY OF CANCER:\")\n",
    "print(df_medical['family_history'].value_counts())\n",
    "print(f\"Percentage:\\n{df_medical['family_history'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Smoking status\n",
    "print(\"\\n5. SMOKING STATUS DISTRIBUTION:\")\n",
    "print(df_medical['smoking_status'].value_counts())\n",
    "print(f\"Percentage:\\n{df_medical['smoking_status'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Treatment type\n",
    "print(\"\\n6. TREATMENT TYPE DISTRIBUTION:\")\n",
    "print(df_medical['treatment_type'].value_counts())\n",
    "print(f\"Percentage:\\n{df_medical['treatment_type'].value_counts(normalize=True) * 100}\")\n",
    "\n",
    "# Survival status\n",
    "print(\"\\n7. SURVIVAL STATUS:\")\n",
    "print(df_medical['survived'].value_counts())\n",
    "survival_rate = df_medical['survived'].mean() * 100\n",
    "print(f\"Survival Rate: {survival_rate:.2f}%\")\n",
    "\n",
    "# Comorbidities\n",
    "print(\"\\n8. COMORBIDITY PREVALENCE:\")\n",
    "print(f\"Hypertension: {df_medical['hypertension'].sum():.0f} patients ({df_medical['hypertension'].mean()*100:.1f}%)\")\n",
    "print(f\"Asthma: {df_medical['asthma'].sum():.0f} patients ({df_medical['asthma'].mean()*100:.1f}%)\")\n",
    "print(f\"Cirrhosis: {df_medical['cirrhosis'].sum():.0f} patients ({df_medical['cirrhosis'].mean()*100:.1f}%)\")\n",
    "print(f\"Other Cancer: {df_medical['other_cancer'].sum():.0f} patients ({df_medical['other_cancer'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c190d7d",
   "metadata": {},
   "source": [
    "# 7. Dataset Geographic Coverage Analysis\n",
    "\n",
    "Comprehensive analysis to verify geographic scope of both datasets - checking all three medical dataset parts and cross-referencing with air pollution data to determine if we have global or regional coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91554e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MEDICAL DATASET COUNTRY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Total unique countries across all parts: 27\n",
      "\n",
      "All countries found:\n",
      "  - Austria\n",
      "  - Belgium\n",
      "  - Bulgaria\n",
      "  - Croatia\n",
      "  - Cyprus\n",
      "  - Czech Republic\n",
      "  - Denmark\n",
      "  - Estonia\n",
      "  - Finland\n",
      "  - France\n",
      "  - Germany\n",
      "  - Greece\n",
      "  - Hungary\n",
      "  - Ireland\n",
      "  - Italy\n",
      "  - Latvia\n",
      "  - Lithuania\n",
      "  - Luxembourg\n",
      "  - Malta\n",
      "  - Netherlands\n",
      "  - Poland\n",
      "  - Portugal\n",
      "  - Romania\n",
      "  - Slovakia\n",
      "  - Slovenia\n",
      "  - Spain\n",
      "  - Sweden\n",
      "\n",
      "============================================================\n",
      "AIR POLLUTION DATASET COUNTRY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Total unique countries: 133\n",
      "\n",
      "All countries found:\n",
      "  - Afghanistan\n",
      "  - Albania\n",
      "  - Algeria\n",
      "  - Andorra\n",
      "  - Angola\n",
      "  - Argentina\n",
      "  - Armenia\n",
      "  - Australia\n",
      "  - Austria\n",
      "  - Azerbaijan\n",
      "  - Bahrain\n",
      "  - Bangladesh\n",
      "  - Belgium\n",
      "  - Belize\n",
      "  - Bermuda\n",
      "  - Bolivia\n",
      "  - Bonaire, Saint Eustatius and Saba\n",
      "  - Bosnia Herzegovina\n",
      "  - Brazil\n",
      "  - Bulgaria\n",
      "  - Burkina Faso\n",
      "  - Cambodia\n",
      "  - Canada\n",
      "  - Chad\n",
      "  - Chile\n",
      "  - China\n",
      "  - Colombia\n",
      "  - Costa Rica\n",
      "  - Croatia\n",
      "  - Cyprus\n",
      "  - Czech Republic\n",
      "  - Democratic Republic of the Congo\n",
      "  - Denmark\n",
      "  - Egypt\n",
      "  - El Salvador\n",
      "  - Estonia\n",
      "  - Ethiopia\n",
      "  - Finland\n",
      "  - France\n",
      "  - French Polynesia\n",
      "  - Gabon\n",
      "  - Georgia\n",
      "  - Germany\n",
      "  - Ghana\n",
      "  - Greece\n",
      "  - Grenada\n",
      "  - Guam\n",
      "  - Guatemala\n",
      "  - Guyana\n",
      "  - Honduras\n",
      "  - Hong Kong SAR\n",
      "  - Hungary\n",
      "  - Iceland\n",
      "  - India\n",
      "  - Indonesia\n",
      "  - Iran\n",
      "  - Iraq\n",
      "  - Ireland\n",
      "  - Israel\n",
      "  - Italy\n",
      "  - Ivory Coast\n",
      "  - Japan\n",
      "  - Kazakhstan\n",
      "  - Kenya\n",
      "  - Kosovo\n",
      "  - Kuwait\n",
      "  - Kyrgyzstan\n",
      "  - Laos\n",
      "  - Latvia\n",
      "  - Liechtenstein\n",
      "  - Lithuania\n",
      "  - Luxembourg\n",
      "  - Macao SAR\n",
      "  - Madagascar\n",
      "  - Malaysia\n",
      "  - Maldives\n",
      "  - Malta\n",
      "  - Mexico\n",
      "  - Moldova\n",
      "  - Mongolia\n",
      "  - Montenegro\n",
      "  - Myanmar\n",
      "  - Nepal\n",
      "  - Netherlands\n",
      "  - New Caledonia\n",
      "  - New Zealand\n",
      "  - Nicaragua\n",
      "  - Nigeria\n",
      "  - North Macedonia\n",
      "  - Norway\n",
      "  - Pakistan\n",
      "  - Panama\n",
      "  - Peru\n",
      "  - Philippines\n",
      "  - Poland\n",
      "  - Portugal\n",
      "  - Puerto Rico\n",
      "  - Qatar\n",
      "  - Romania\n",
      "  - Russia\n",
      "  - Rwanda\n",
      "  - Saudi Arabia\n",
      "  - Senegal\n",
      "  - Serbia\n",
      "  - Singapore\n",
      "  - Slovakia\n",
      "  - Slovenia\n",
      "  - South Africa\n",
      "  - South Korea\n",
      "  - Spain\n",
      "  - Sri Lanka\n",
      "  - Sudan\n",
      "  - Suriname\n",
      "  - Sweden\n",
      "  - Switzerland\n",
      "  - Syria\n",
      "  - Taiwan\n",
      "  - Tajikistan\n",
      "  - Thailand\n",
      "  - Trinidad and Tobago\n",
      "  - Turkey\n",
      "  - Turkmenistan\n",
      "  - U.S. Virgin Islands\n",
      "  - USA\n",
      "  - Uganda\n",
      "  - Ukraine\n",
      "  - United Arab Emirates\n",
      "  - United Kingdom\n",
      "  - Uruguay\n",
      "  - Uzbekistan\n",
      "  - Venezuela\n",
      "  - Vietnam\n",
      "  - Zambia\n",
      "\n",
      "============================================================\n",
      "CROSS-REFERENCE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "‚úì All medical dataset countries have air pollution data!\n",
      "\n",
      "‚ö†Ô∏è Countries in AIR POLLUTION dataset but NOT in MEDICAL dataset (106):\n",
      "  - Afghanistan\n",
      "  - Albania\n",
      "  - Algeria\n",
      "  - Andorra\n",
      "  - Angola\n",
      "  - Argentina\n",
      "  - Armenia\n",
      "  - Australia\n",
      "  - Azerbaijan\n",
      "  - Bahrain\n",
      "  - Bangladesh\n",
      "  - Belize\n",
      "  - Bermuda\n",
      "  - Bolivia\n",
      "  - Bonaire, Saint Eustatius and Saba\n",
      "  - Bosnia Herzegovina\n",
      "  - Brazil\n",
      "  - Burkina Faso\n",
      "  - Cambodia\n",
      "  - Canada\n",
      "  - Chad\n",
      "  - Chile\n",
      "  - China\n",
      "  - Colombia\n",
      "  - Costa Rica\n",
      "  - Democratic Republic of the Congo\n",
      "  - Egypt\n",
      "  - El Salvador\n",
      "  - Ethiopia\n",
      "  - French Polynesia\n",
      "  - Gabon\n",
      "  - Georgia\n",
      "  - Ghana\n",
      "  - Grenada\n",
      "  - Guam\n",
      "  - Guatemala\n",
      "  - Guyana\n",
      "  - Honduras\n",
      "  - Hong Kong SAR\n",
      "  - Iceland\n",
      "  - India\n",
      "  - Indonesia\n",
      "  - Iran\n",
      "  - Iraq\n",
      "  - Israel\n",
      "  - Ivory Coast\n",
      "  - Japan\n",
      "  - Kazakhstan\n",
      "  - Kenya\n",
      "  - Kosovo\n",
      "  - Kuwait\n",
      "  - Kyrgyzstan\n",
      "  - Laos\n",
      "  - Liechtenstein\n",
      "  - Macao SAR\n",
      "  - Madagascar\n",
      "  - Malaysia\n",
      "  - Maldives\n",
      "  - Mexico\n",
      "  - Moldova\n",
      "  - Mongolia\n",
      "  - Montenegro\n",
      "  - Myanmar\n",
      "  - Nepal\n",
      "  - New Caledonia\n",
      "  - New Zealand\n",
      "  - Nicaragua\n",
      "  - Nigeria\n",
      "  - North Macedonia\n",
      "  - Norway\n",
      "  - Pakistan\n",
      "  - Panama\n",
      "  - Peru\n",
      "  - Philippines\n",
      "  - Puerto Rico\n",
      "  - Qatar\n",
      "  - Russia\n",
      "  - Rwanda\n",
      "  - Saudi Arabia\n",
      "  - Senegal\n",
      "  - Serbia\n",
      "  - Singapore\n",
      "  - South Africa\n",
      "  - South Korea\n",
      "  - Sri Lanka\n",
      "  - Sudan\n",
      "  - Suriname\n",
      "  - Switzerland\n",
      "  - Syria\n",
      "  - Taiwan\n",
      "  - Tajikistan\n",
      "  - Thailand\n",
      "  - Trinidad and Tobago\n",
      "  - Turkey\n",
      "  - Turkmenistan\n",
      "  - U.S. Virgin Islands\n",
      "  - USA\n",
      "  - Uganda\n",
      "  - Ukraine\n",
      "  - United Arab Emirates\n",
      "  - United Kingdom\n",
      "  - Uruguay\n",
      "  - Uzbekistan\n",
      "  - Venezuela\n",
      "  - Vietnam\n",
      "  - Zambia\n",
      "\n",
      "‚úì Countries with BOTH medical and air pollution data (27):\n",
      "  - Austria\n",
      "  - Belgium\n",
      "  - Bulgaria\n",
      "  - Croatia\n",
      "  - Cyprus\n",
      "  - Czech Republic\n",
      "  - Denmark\n",
      "  - Estonia\n",
      "  - Finland\n",
      "  - France\n",
      "  - Germany\n",
      "  - Greece\n",
      "  - Hungary\n",
      "  - Ireland\n",
      "  - Italy\n",
      "  - Latvia\n",
      "  - Lithuania\n",
      "  - Luxembourg\n",
      "  - Malta\n",
      "  - Netherlands\n",
      "  - Poland\n",
      "  - Portugal\n",
      "  - Romania\n",
      "  - Slovakia\n",
      "  - Slovenia\n",
      "  - Spain\n",
      "  - Sweden\n",
      "\n",
      "============================================================\n",
      "GEOGRAPHIC SCOPE VERIFICATION\n",
      "============================================================\n",
      "\n",
      "‚úì All medical dataset countries are EUROPEAN!\n",
      "\n",
      "‚ö†Ô∏è NON-EUROPEAN countries found in AIR POLLUTION dataset (92):\n",
      "  - Afghanistan\n",
      "  - Algeria\n",
      "  - Angola\n",
      "  - Argentina\n",
      "  - Armenia\n",
      "  - Australia\n",
      "  - Azerbaijan\n",
      "  - Bahrain\n",
      "  - Bangladesh\n",
      "  - Belize\n",
      "  - Bermuda\n",
      "  - Bolivia\n",
      "  - Bonaire, Saint Eustatius and Saba\n",
      "  - Bosnia Herzegovina\n",
      "  - Brazil\n",
      "  - Burkina Faso\n",
      "  - Cambodia\n",
      "  - Canada\n",
      "  - Chad\n",
      "  - Chile\n",
      "  - China\n",
      "  - Colombia\n",
      "  - Costa Rica\n",
      "  - Democratic Republic of the Congo\n",
      "  - Egypt\n",
      "  - El Salvador\n",
      "  - Ethiopia\n",
      "  - French Polynesia\n",
      "  - Gabon\n",
      "  - Georgia\n",
      "  - Ghana\n",
      "  - Grenada\n",
      "  - Guam\n",
      "  - Guatemala\n",
      "  - Guyana\n",
      "  - Honduras\n",
      "  - Hong Kong SAR\n",
      "  - India\n",
      "  - Indonesia\n",
      "  - Iran\n",
      "  - Iraq\n",
      "  - Israel\n",
      "  - Ivory Coast\n",
      "  - Japan\n",
      "  - Kazakhstan\n",
      "  - Kenya\n",
      "  - Kuwait\n",
      "  - Kyrgyzstan\n",
      "  - Laos\n",
      "  - Macao SAR\n",
      "  - Madagascar\n",
      "  - Malaysia\n",
      "  - Maldives\n",
      "  - Mexico\n",
      "  - Mongolia\n",
      "  - Myanmar\n",
      "  - Nepal\n",
      "  - New Caledonia\n",
      "  - New Zealand\n",
      "  - Nicaragua\n",
      "  - Nigeria\n",
      "  - Pakistan\n",
      "  - Panama\n",
      "  - Peru\n",
      "  - Philippines\n",
      "  - Puerto Rico\n",
      "  - Qatar\n",
      "  - Rwanda\n",
      "  - Saudi Arabia\n",
      "  - Senegal\n",
      "  - Singapore\n",
      "  - South Africa\n",
      "  - South Korea\n",
      "  - Sri Lanka\n",
      "  - Sudan\n",
      "  - Suriname\n",
      "  - Syria\n",
      "  - Taiwan\n",
      "  - Tajikistan\n",
      "  - Thailand\n",
      "  - Trinidad and Tobago\n",
      "  - Turkey\n",
      "  - Turkmenistan\n",
      "  - U.S. Virgin Islands\n",
      "  - USA\n",
      "  - Uganda\n",
      "  - United Arab Emirates\n",
      "  - Uruguay\n",
      "  - Uzbekistan\n",
      "  - Venezuela\n",
      "  - Vietnam\n",
      "  - Zambia\n",
      "\n",
      "============================================================\n",
      "FINAL VERDICT\n",
      "============================================================\n",
      "\n",
      "‚ö†Ô∏è MIXED: Dataset contains non-European countries\n",
      "   Review the non-European countries listed above\n",
      "\n",
      "   - Medical dataset: 27 total (0 non-European)\n",
      "   - Air pollution dataset: 133 total (92 non-European)\n",
      "   - Countries with both datasets: 27\n",
      "\n",
      "üìå RECOMMENDATION: Consider 'Global Analysis' if sufficient non-European coverage\n"
     ]
    }
   ],
   "source": [
    "# Check all three parts of medical dataset\n",
    "df_part1 = pd.read_csv('../datasets/lung_cancer_part1.csv')\n",
    "df_part2 = pd.read_csv('../datasets/lung_cancer_part2.csv')\n",
    "df_part3 = pd.read_csv('../datasets/lung_cancer_part3.csv')\n",
    "\n",
    "# Get unique countries from each part\n",
    "countries_part1 = set(df_part1['country'].unique())\n",
    "countries_part2 = set(df_part2['country'].unique())\n",
    "countries_part3 = set(df_part3['country'].unique())\n",
    "\n",
    "# Combine all unique countries\n",
    "all_medical_countries = countries_part1.union(countries_part2).union(countries_part3)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MEDICAL DATASET COUNTRY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal unique countries across all parts: {len(all_medical_countries)}\")\n",
    "print(f\"\\nAll countries found:\")\n",
    "for country in sorted(all_medical_countries):\n",
    "    print(f\"  - {country}\")\n",
    "\n",
    "# Load air pollution dataset\n",
    "pollution_countries = set(df_pollution['country'].unique())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AIR POLLUTION DATASET COUNTRY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal unique countries: {len(pollution_countries)}\")\n",
    "print(f\"\\nAll countries found:\")\n",
    "for country in sorted(pollution_countries):\n",
    "    print(f\"  - {country}\")\n",
    "\n",
    "# Cross-reference\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CROSS-REFERENCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Countries in medical but NOT in pollution\n",
    "missing_in_pollution = all_medical_countries - pollution_countries\n",
    "if missing_in_pollution:\n",
    "    print(f\"\\n‚ö†Ô∏è Countries in MEDICAL dataset but NOT in AIR POLLUTION dataset ({len(missing_in_pollution)}):\")\n",
    "    for country in sorted(missing_in_pollution):\n",
    "        print(f\"  - {country}\")\n",
    "else:\n",
    "    print(\"\\n‚úì All medical dataset countries have air pollution data!\")\n",
    "\n",
    "# Countries in pollution but NOT in medical\n",
    "missing_in_medical = pollution_countries - all_medical_countries\n",
    "if missing_in_medical:\n",
    "    print(f\"\\n‚ö†Ô∏è Countries in AIR POLLUTION dataset but NOT in MEDICAL dataset ({len(missing_in_medical)}):\")\n",
    "    for country in sorted(missing_in_medical):\n",
    "        print(f\"  - {country}\")\n",
    "else:\n",
    "    print(\"\\n‚úì All air pollution countries have medical data!\")\n",
    "\n",
    "# Perfect matches\n",
    "matching_countries = all_medical_countries.intersection(pollution_countries)\n",
    "print(f\"\\n‚úì Countries with BOTH medical and air pollution data ({len(matching_countries)}):\")\n",
    "for country in sorted(matching_countries):\n",
    "    print(f\"  - {country}\")\n",
    "\n",
    "# Check if all are European\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GEOGRAPHIC SCOPE VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "european_countries = {\n",
    "    'Albania', 'Andorra', 'Austria', 'Belarus', 'Belgium', 'Bosnia and Herzegovina',\n",
    "    'Bulgaria', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark', 'Estonia', \n",
    "    'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Iceland', 'Ireland',\n",
    "    'Italy', 'Kosovo', 'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg',\n",
    "    'Malta', 'Moldova', 'Monaco', 'Montenegro', 'Netherlands', 'North Macedonia',\n",
    "    'Norway', 'Poland', 'Portugal', 'Romania', 'Russia', 'San Marino', 'Serbia',\n",
    "    'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'Ukraine', \n",
    "    'United Kingdom', 'Vatican City'\n",
    "}\n",
    "\n",
    "non_european_medical = all_medical_countries - european_countries\n",
    "non_european_pollution = pollution_countries - european_countries\n",
    "\n",
    "if non_european_medical:\n",
    "    print(f\"\\n‚ö†Ô∏è NON-EUROPEAN countries found in MEDICAL dataset ({len(non_european_medical)}):\")\n",
    "    for country in sorted(non_european_medical):\n",
    "        print(f\"  - {country}\")\n",
    "else:\n",
    "    print(\"\\n‚úì All medical dataset countries are EUROPEAN!\")\n",
    "\n",
    "if non_european_pollution:\n",
    "    print(f\"\\n‚ö†Ô∏è NON-EUROPEAN countries found in AIR POLLUTION dataset ({len(non_european_pollution)}):\")\n",
    "    for country in sorted(non_european_pollution):\n",
    "        print(f\"  - {country}\")\n",
    "else:\n",
    "    print(\"\\n‚úì All air pollution dataset countries are EUROPEAN!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL VERDICT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not non_european_medical and not non_european_pollution:\n",
    "    print(\"\\n‚úÖ CONFIRMED: All data is strictly EUROPEAN\")\n",
    "    print(f\"   - Medical dataset: {len(all_medical_countries)} European countries\")\n",
    "    print(f\"   - Air pollution dataset: {len(pollution_countries)} European countries\")\n",
    "    print(f\"   - Countries with both datasets: {len(matching_countries)}\")\n",
    "    print(\"\\nüìå RECOMMENDATION: Keep project scope as 'European Analysis'\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è MIXED: Dataset contains non-European countries\")\n",
    "    print(\"   Review the non-European countries listed above\")\n",
    "    print(f\"\\n   - Medical dataset: {len(all_medical_countries)} total ({len(non_european_medical)} non-European)\")\n",
    "    print(f\"   - Air pollution dataset: {len(pollution_countries)} total ({len(non_european_pollution)} non-European)\")\n",
    "    print(f\"   - Countries with both datasets: {len(matching_countries)}\")\n",
    "    print(\"\\nüìå RECOMMENDATION: Consider 'Global Analysis' if sufficient non-European coverage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9364a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PLACEHOLDER FOR ADDITIONAL ANALYSIS SECTIONS\n",
    "\n",
    "The following sections will be added:\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Data Visualizations (charts, plots, heatmaps)\n",
    "- Correlation Analysis\n",
    "- Statistical Testing\n",
    "- Pollution-Cancer Correlation Analysis\n",
    "- Insights and Conclusions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c621d10",
   "metadata": {},
   "source": [
    "# 8. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5405e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Age distribution analysis\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_medical['age'], bins=30, edgecolor='black')\n",
    "plt.title('Age Distribution of Lung Cancer Patients')\n",
    "plt.xlabel('Age (Normalized)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# BMI distribution by survival status\n",
    "plt.subplot(1, 2, 2)\n",
    "df_medical.boxplot(column='bmi', by='survived')\n",
    "plt.title('BMI Distribution by Survival Status')\n",
    "plt.suptitle('')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
